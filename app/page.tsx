'use client'

import { useState, useEffect, useRef, useCallback } from 'react'
import RobotAvatar from '@/components/RobotAvatar'
import ChatBubble from '@/components/ChatBubble'
import VoiceButton from '@/components/VoiceButton'
import StatusIndicator from '@/components/StatusIndicator'

type RobotState = 'idle' | 'listening' | 'thinking' | 'speaking'

interface Message {
  role: 'user' | 'assistant'
  content: string
}

export default function Home() {
  const [robotState, setRobotState] = useState<RobotState>('idle')
  const [messages, setMessages] = useState<Message[]>([])
  const [threadId, setThreadId] = useState<string | null>(null)
  const [micPermission, setMicPermission] = useState<'granted' | 'denied' | 'prompt'>('prompt')
  const [errorMessage, setErrorMessage] = useState<string | null>(null)
  const [recordingTime, setRecordingTime] = useState(0)
  
  const audioRef = useRef<HTMLAudioElement | null>(null)
  const chatContainerRef = useRef<HTMLDivElement>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const streamRef = useRef<MediaStream | null>(null)
  const timerRef = useRef<NodeJS.Timeout | null>(null)
  
  const robotStateRef = useRef<RobotState>('idle')
  
  useEffect(() => {
    robotStateRef.current = robotState
  }, [robotState])

  // è‡ªå‹•æ»¾å‹•
  useEffect(() => {
    if (chatContainerRef.current) {
      chatContainerRef.current.scrollTop = chatContainerRef.current.scrollHeight
    }
  }, [messages])

  // æ¸…ç†
  useEffect(() => {
    return () => {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop())
      }
      if (timerRef.current) {
        clearInterval(timerRef.current)
      }
    }
  }, [])

  // è«‹æ±‚éº¥å…‹é¢¨æ¬Šé™
  const requestMicPermission = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 16000,
        } 
      })
      streamRef.current = stream
      setMicPermission('granted')
      setErrorMessage(null)
      return stream
    } catch (error) {
      console.error('Microphone permission error:', error)
      setMicPermission('denied')
      setErrorMessage('è«‹å…è¨±éº¥å…‹é¢¨æ¬Šé™æ‰èƒ½ä½¿ç”¨èªéŸ³åŠŸèƒ½')
      return null
    }
  }, [])

  // ç™¼é€è¨Šæ¯çµ¦ AI
  const sendToAssistant = useCallback(async (userMessage: string) => {
    setRobotState('thinking')
    setMessages(prev => [...prev, { role: 'user', content: userMessage }])

    try {
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ message: userMessage, threadId })
      })

      if (!response.ok) throw new Error('Chat failed')

      const data = await response.json()
      
      if (data.threadId) {
        setThreadId(data.threadId)
      }

      const assistantMessage = data.message
      setMessages(prev => [...prev, { role: 'assistant', content: assistantMessage }])

      // æ’­æ”¾ TTS
      setRobotState('speaking')
      
      const ttsResponse = await fetch('/api/tts', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text: assistantMessage })
      })

      if (ttsResponse.ok && audioRef.current) {
        const audioBlob = await ttsResponse.blob()
        const audioUrl = URL.createObjectURL(audioBlob)
        audioRef.current.src = audioUrl
        audioRef.current.onended = () => {
          setRobotState('idle')
          URL.revokeObjectURL(audioUrl)
        }
        await audioRef.current.play()
      } else {
        setRobotState('idle')
      }

    } catch (error) {
      console.error('Chat error:', error)
      setMessages(prev => [...prev, { role: 'assistant', content: 'æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›å•é¡Œï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚' }])
      setRobotState('idle')
    }
  }, [threadId])

  // ä½¿ç”¨ Whisper API è½‰éŒ„éŸ³è¨Š
  const transcribeAudio = useCallback(async (audioBlob: Blob) => {
    setRobotState('thinking')
    
    try {
      // å»ºç«‹ FormData
      const formData = new FormData()
      formData.append('audio', audioBlob, 'recording.webm')

      const response = await fetch('/api/transcribe', {
        method: 'POST',
        body: formData,
      })

      if (!response.ok) {
        throw new Error('Transcription failed')
      }

      const data = await response.json()
      const text = data.text?.trim()

      if (text) {
        await sendToAssistant(text)
      } else {
        setErrorMessage('æ²’æœ‰è­˜åˆ¥åˆ°èªéŸ³å…§å®¹ï¼Œè«‹å†è©¦ä¸€æ¬¡')
        setRobotState('idle')
      }

    } catch (error) {
      console.error('Transcription error:', error)
      setErrorMessage('èªéŸ³è­˜åˆ¥å¤±æ•—ï¼Œè«‹å†è©¦ä¸€æ¬¡')
      setRobotState('idle')
    }
  }, [sendToAssistant])

  // é–‹å§‹éŒ„éŸ³
  const startListening = useCallback(async () => {
    if (robotStateRef.current !== 'idle') return

    setErrorMessage(null)

    // å–å¾—æˆ–è«‹æ±‚éº¥å…‹é¢¨æ¬Šé™
    let stream = streamRef.current
    if (!stream || !stream.active) {
      stream = await requestMicPermission()
      if (!stream) return
    }

    try {
      // é‡ç½®éŒ„éŸ³æ•¸æ“š
      audioChunksRef.current = []
      setRecordingTime(0)

      // æ±ºå®šæ”¯æ´çš„æ ¼å¼
      let mimeType = 'audio/webm'
      if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
        mimeType = 'audio/webm;codecs=opus'
      } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
        mimeType = 'audio/mp4'
      } else if (MediaRecorder.isTypeSupported('audio/wav')) {
        mimeType = 'audio/wav'
      }

      const mediaRecorder = new MediaRecorder(stream, { mimeType })
      mediaRecorderRef.current = mediaRecorder

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data)
        }
      }

      mediaRecorder.onstop = async () => {
        if (timerRef.current) {
          clearInterval(timerRef.current)
          timerRef.current = null
        }

        if (audioChunksRef.current.length > 0) {
          const audioBlob = new Blob(audioChunksRef.current, { type: mimeType })
          
          // æª¢æŸ¥éŒ„éŸ³é•·åº¦
          if (audioBlob.size < 1000) {
            setErrorMessage('éŒ„éŸ³æ™‚é–“å¤ªçŸ­ï¼Œè«‹èªªé•·ä¸€é»')
            setRobotState('idle')
            return
          }

          await transcribeAudio(audioBlob)
        } else {
          setRobotState('idle')
        }
      }

      mediaRecorder.onerror = (event) => {
        console.error('MediaRecorder error:', event)
        setErrorMessage('éŒ„éŸ³ç™¼ç”ŸéŒ¯èª¤')
        setRobotState('idle')
      }

      // é–‹å§‹éŒ„éŸ³
      mediaRecorder.start(100) // æ¯ 100ms æ”¶é›†ä¸€æ¬¡æ•¸æ“š
      setRobotState('listening')

      // è¨ˆæ™‚å™¨
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => {
          // æœ€é•· 30 ç§’è‡ªå‹•åœæ­¢
          if (prev >= 30) {
            stopListening()
            return prev
          }
          return prev + 1
        })
      }, 1000)

    } catch (error) {
      console.error('Failed to start recording:', error)
      setErrorMessage('ç„¡æ³•å•Ÿå‹•éŒ„éŸ³')
      setRobotState('idle')
    }
  }, [requestMicPermission, transcribeAudio])

  // åœæ­¢éŒ„éŸ³
  const stopListening = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop()
    }
    if (timerRef.current) {
      clearInterval(timerRef.current)
      timerRef.current = null
    }
  }, [])

  // è™•ç†æŒ‰éˆ•é»æ“Š
  const handleVoiceButtonPress = useCallback(() => {
    if (robotStateRef.current === 'listening') {
      stopListening()
    } else if (robotStateRef.current === 'idle') {
      startListening()
    }
  }, [startListening, stopListening])

  return (
    <main className="h-screen flex flex-col overflow-hidden">
      <audio ref={audioRef} playsInline />

      {/* é ‚éƒ¨ç‹€æ…‹åˆ— */}
      <header className="flex-none px-4 py-3 flex items-center justify-between bg-black/20 backdrop-blur-sm">
        <div className="flex items-center gap-2">
          <StatusIndicator state={robotState} />
          <span className="text-sm text-gray-300">
            {robotState === 'idle' && 'å¾…æ©Ÿä¸­'}
            {robotState === 'listening' && `éŒ„éŸ³ä¸­ ${recordingTime}s`}
            {robotState === 'thinking' && 'è™•ç†ä¸­...'}
            {robotState === 'speaking' && 'å›è¦†ä¸­...'}
          </span>
        </div>
        
        {micPermission === 'granted' && (
          <span className="text-xs text-green-400">ğŸ¤ å·²æˆæ¬Š</span>
        )}
      </header>

      {/* éŒ¯èª¤è¨Šæ¯ */}
      {errorMessage && (
        <div className="mx-4 mt-2 p-3 bg-red-500/20 border border-red-500/30 rounded-lg text-red-300 text-sm text-center">
          {errorMessage}
          <button 
            onClick={() => setErrorMessage(null)}
            className="ml-2 text-red-400 hover:text-red-300"
          >
            âœ•
          </button>
        </div>
      )}

      {/* æ©Ÿå™¨äººå‹•ç•«å€ */}
      <section className="flex-none h-[32vh] flex items-center justify-center">
        <RobotAvatar state={robotState} />
      </section>

      {/* å°è©±å€ */}
      <section 
        ref={chatContainerRef}
        className="flex-1 overflow-y-auto px-4 pb-4 space-y-3"
      >
        {messages.length === 0 && (
          <div className="text-center text-gray-400 mt-4">
            <p className="text-lg mb-2">ğŸ‘‹ ä½ å¥½ï¼æˆ‘æ˜¯æ™ºæ…§å®¢æœåŠ©ç†</p>
            <p className="text-sm mb-4">é»æ“Šéº¥å…‹é¢¨æŒ‰éˆ•é–‹å§‹éŒ„éŸ³ï¼Œå†æ¬¡é»æ“Šåœæ­¢</p>
            
            {micPermission === 'prompt' && (
              <button
                onClick={requestMicPermission}
                className="px-4 py-2 bg-robot-blue/20 text-robot-blue rounded-full text-sm hover:bg-robot-blue/30 transition-colors"
              >
                ğŸ¤ é»æ“Šæˆæ¬Šéº¥å…‹é¢¨
              </button>
            )}
          </div>
        )}
        
        {messages.map((msg, index) => (
          <ChatBubble 
            key={index} 
            role={msg.role} 
            content={msg.content} 
          />
        ))}

        {/* æ€è€ƒä¸­ */}
        {robotState === 'thinking' && (
          <div className="flex justify-center gap-1 py-2">
            <span className="thinking-dot w-2 h-2 bg-robot-blue rounded-full"></span>
            <span className="thinking-dot w-2 h-2 bg-robot-blue rounded-full"></span>
            <span className="thinking-dot w-2 h-2 bg-robot-blue rounded-full"></span>
          </div>
        )}
      </section>

      {/* åº•éƒ¨æ§åˆ¶å€ */}
      <footer className="flex-none px-4 py-6 bg-gradient-to-t from-black/40 to-transparent">
        <div className="flex items-center justify-center gap-4">
          <VoiceButton 
            state={robotState}
            onPress={handleVoiceButtonPress}
            onRelease={() => {}}
            disabled={robotState === 'thinking' || robotState === 'speaking'}
          />
        </div>
        
        <p className="text-center text-xs text-gray-500 mt-4">
          {robotState === 'listening' 
            ? 'é»æ“ŠæŒ‰éˆ•åœæ­¢éŒ„éŸ³' 
            : micPermission === 'denied' 
            ? 'è«‹å…ˆæˆæ¬Šéº¥å…‹é¢¨æ¬Šé™' 
            : 'é»æ“ŠæŒ‰éˆ•é–‹å§‹éŒ„éŸ³'}
        </p>
      </footer>
    </main>
  )
}
