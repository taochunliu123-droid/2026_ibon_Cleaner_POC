'use client'

import { useState, useEffect, useRef, useCallback } from 'react'
import RobotAvatar from '@/components/RobotAvatar'
import ChatBubble from '@/components/ChatBubble'
import VoiceButton from '@/components/VoiceButton'
import StatusIndicator from '@/components/StatusIndicator'

type RobotState = 'idle' | 'listening' | 'thinking' | 'speaking'

interface Message {
  role: 'user' | 'assistant'
  content: string
}

export default function Home() {
  const [robotState, setRobotState] = useState<RobotState>('idle')
  const [messages, setMessages] = useState<Message[]>([])
  const [currentTranscript, setCurrentTranscript] = useState('')
  const [isWakeWordMode, setIsWakeWordMode] = useState(false)
  const [threadId, setThreadId] = useState<string | null>(null)
  
  const recognitionRef = useRef<SpeechRecognition | null>(null)
  const audioRef = useRef<HTMLAudioElement | null>(null)
  const chatContainerRef = useRef<HTMLDivElement>(null)

  // åˆå§‹åŒ–èªéŸ³è­˜åˆ¥
  useEffect(() => {
    if (typeof window !== 'undefined') {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
      if (SpeechRecognition) {
        const recognition = new SpeechRecognition()
        recognition.continuous = true
        recognition.interimResults = true
        recognition.lang = 'zh-TW'
        recognitionRef.current = recognition
      }
    }
  }, [])

  // è‡ªå‹•æ»¾å‹•åˆ°æœ€æ–°è¨Šæ¯
  useEffect(() => {
    if (chatContainerRef.current) {
      chatContainerRef.current.scrollTop = chatContainerRef.current.scrollHeight
    }
  }, [messages])

  // æ’­æ”¾ TTS èªéŸ³
  const playTTS = async (text: string) => {
    try {
      setRobotState('speaking')
      
      const response = await fetch('/api/tts', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text })
      })

      if (!response.ok) throw new Error('TTS failed')

      const audioBlob = await response.blob()
      const audioUrl = URL.createObjectURL(audioBlob)
      
      if (audioRef.current) {
        audioRef.current.src = audioUrl
        audioRef.current.onended = () => {
          setRobotState('idle')
          URL.revokeObjectURL(audioUrl)
          // å¦‚æœåœ¨å–šé†’è©æ¨¡å¼ï¼Œç¹¼çºŒç›£è½
          if (isWakeWordMode) {
            startWakeWordListening()
          }
        }
        await audioRef.current.play()
      }
    } catch (error) {
      console.error('TTS error:', error)
      setRobotState('idle')
    }
  }

  // ç™¼é€è¨Šæ¯çµ¦ AI
  const sendToAssistant = async (userMessage: string) => {
    setRobotState('thinking')
    
    // æ·»åŠ ç”¨æˆ¶è¨Šæ¯
    setMessages(prev => [...prev, { role: 'user', content: userMessage }])

    try {
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          message: userMessage,
          threadId 
        })
      })

      if (!response.ok) throw new Error('Chat failed')

      const data = await response.json()
      
      // ä¿å­˜ thread ID
      if (data.threadId) {
        setThreadId(data.threadId)
      }

      // æ·»åŠ  AI å›æ‡‰
      const assistantMessage = data.message
      setMessages(prev => [...prev, { role: 'assistant', content: assistantMessage }])

      // æ’­æ”¾èªéŸ³
      await playTTS(assistantMessage)

    } catch (error) {
      console.error('Chat error:', error)
      const errorMsg = 'æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›å•é¡Œï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚'
      setMessages(prev => [...prev, { role: 'assistant', content: errorMsg }])
      await playTTS(errorMsg)
    }
  }

  // é–‹å§‹æŒ‰éˆ•å¼èªéŸ³è­˜åˆ¥
  const startListening = useCallback(() => {
    if (!recognitionRef.current || robotState !== 'idle') return

    setRobotState('listening')
    setCurrentTranscript('')

    const recognition = recognitionRef.current
    
    recognition.onresult = (event) => {
      let finalTranscript = ''
      let interimTranscript = ''

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript
        if (event.results[i].isFinal) {
          finalTranscript += transcript
        } else {
          interimTranscript += transcript
        }
      }

      setCurrentTranscript(interimTranscript || finalTranscript)

      if (finalTranscript) {
        recognition.stop()
        sendToAssistant(finalTranscript)
      }
    }

    recognition.onerror = (event) => {
      console.error('Speech recognition error:', event.error)
      setRobotState('idle')
    }

    recognition.onend = () => {
      if (robotState === 'listening') {
        // å¦‚æœæ²’æœ‰çµæœå°±çµæŸ
        setRobotState('idle')
      }
    }

    recognition.start()
  }, [robotState])

  // åœæ­¢èªéŸ³è­˜åˆ¥
  const stopListening = useCallback(() => {
    if (recognitionRef.current) {
      recognitionRef.current.stop()
    }
  }, [])

  // å–šé†’è©ç›£è½æ¨¡å¼
  const startWakeWordListening = useCallback(() => {
    if (!recognitionRef.current || robotState === 'speaking' || robotState === 'thinking') return

    const recognition = recognitionRef.current
    recognition.continuous = true

    recognition.onresult = (event) => {
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript.toLowerCase()
        
        // æª¢æ¸¬å–šé†’è©
        if (transcript.includes('ä½ å¥½') || transcript.includes('å“ˆå›‰') || transcript.includes('å—¨')) {
          recognition.stop()
          setIsWakeWordMode(false)
          
          // æ’­æ”¾å–šé†’å›æ‡‰
          const greeting = 'ä½ å¥½ï¼æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«åŠ©ä½ çš„å—ï¼Ÿ'
          setMessages(prev => [...prev, { role: 'assistant', content: greeting }])
          playTTS(greeting)
          return
        }

        // å¦‚æœä¸æ˜¯å–šé†’è©ä½†å·²ç¶“åœ¨å°è©±ä¸­ï¼Œè™•ç†ä¸€èˆ¬è¨Šæ¯
        if (event.results[i].isFinal && !isWakeWordMode) {
          const finalTranscript = event.results[i][0].transcript
          if (finalTranscript.trim()) {
            recognition.stop()
            sendToAssistant(finalTranscript)
          }
        }
      }
    }

    recognition.onerror = (event) => {
      console.error('Wake word error:', event.error)
      // 5ç§’å¾Œé‡æ–°é–‹å§‹ç›£è½
      setTimeout(() => {
        if (isWakeWordMode) startWakeWordListening()
      }, 5000)
    }

    recognition.onend = () => {
      // æŒçºŒç›£è½
      if (isWakeWordMode && robotState === 'idle') {
        setTimeout(() => startWakeWordListening(), 100)
      }
    }

    try {
      recognition.start()
    } catch (e) {
      console.error('Failed to start recognition:', e)
    }
  }, [robotState, isWakeWordMode])

  // åˆ‡æ›å–šé†’è©æ¨¡å¼
  const toggleWakeWordMode = () => {
    if (isWakeWordMode) {
      setIsWakeWordMode(false)
      stopListening()
    } else {
      setIsWakeWordMode(true)
      startWakeWordListening()
    }
  }

  return (
    <main className="h-screen flex flex-col overflow-hidden">
      {/* éš±è—çš„éŸ³è¨Šå…ƒç´  */}
      <audio ref={audioRef} />

      {/* é ‚éƒ¨ç‹€æ…‹åˆ— */}
      <header className="flex-none px-4 py-3 flex items-center justify-between bg-black/20 backdrop-blur-sm">
        <div className="flex items-center gap-2">
          <StatusIndicator state={robotState} />
          <span className="text-sm text-gray-300">
            {robotState === 'idle' && 'å¾…æ©Ÿä¸­'}
            {robotState === 'listening' && 'è†è½ä¸­...'}
            {robotState === 'thinking' && 'æ€è€ƒä¸­...'}
            {robotState === 'speaking' && 'å›è¦†ä¸­...'}
          </span>
        </div>
        
        {/* å–šé†’è©æ¨¡å¼é–‹é—œ */}
        <button
          onClick={toggleWakeWordMode}
          className={`px-3 py-1.5 rounded-full text-xs font-medium transition-all ${
            isWakeWordMode 
              ? 'bg-robot-blue text-black' 
              : 'bg-white/10 text-gray-300 hover:bg-white/20'
          }`}
        >
          {isWakeWordMode ? 'ğŸ¤ å–šé†’è©é–‹å•Ÿ' : 'å–šé†’è©é—œé–‰'}
        </button>
      </header>

      {/* æ©Ÿå™¨äººå‹•ç•«å€ */}
      <section className="flex-none h-[35vh] flex items-center justify-center">
        <RobotAvatar state={robotState} />
      </section>

      {/* å°è©±å€ */}
      <section 
        ref={chatContainerRef}
        className="flex-1 overflow-y-auto px-4 pb-4 space-y-3"
      >
        {messages.length === 0 && (
          <div className="text-center text-gray-400 mt-8">
            <p className="text-lg mb-2">ğŸ‘‹ ä½ å¥½ï¼æˆ‘æ˜¯æ™ºæ…§å®¢æœåŠ©ç†</p>
            <p className="text-sm">é»æ“Šä¸‹æ–¹éº¥å…‹é¢¨æŒ‰éˆ•ï¼Œæˆ–èªªã€Œä½ å¥½ã€é–‹å§‹å°è©±</p>
          </div>
        )}
        
        {messages.map((msg, index) => (
          <ChatBubble 
            key={index} 
            role={msg.role} 
            content={msg.content} 
          />
        ))}

        {/* å³æ™‚è½‰éŒ„é¡¯ç¤º */}
        {currentTranscript && robotState === 'listening' && (
          <div className="text-center text-robot-blue/70 text-sm italic">
            "{currentTranscript}"
          </div>
        )}

        {/* æ€è€ƒä¸­æç¤º */}
        {robotState === 'thinking' && (
          <div className="flex justify-center gap-1">
            <span className="thinking-dot w-2 h-2 bg-robot-blue rounded-full"></span>
            <span className="thinking-dot w-2 h-2 bg-robot-blue rounded-full"></span>
            <span className="thinking-dot w-2 h-2 bg-robot-blue rounded-full"></span>
          </div>
        )}
      </section>

      {/* åº•éƒ¨æ§åˆ¶å€ */}
      <footer className="flex-none px-4 py-6 bg-gradient-to-t from-black/40 to-transparent">
        <div className="flex items-center justify-center gap-4">
          <VoiceButton 
            state={robotState}
            onPress={startListening}
            onRelease={stopListening}
            disabled={robotState !== 'idle'}
          />
        </div>
        
        <p className="text-center text-xs text-gray-500 mt-3">
          {isWakeWordMode ? 'èªªã€Œä½ å¥½ã€æˆ–ã€Œå—¨ã€ä¾†å–šé†’æˆ‘' : 'æŒ‰ä½æŒ‰éˆ•èªªè©±'}
        </p>
      </footer>
    </main>
  )
}
